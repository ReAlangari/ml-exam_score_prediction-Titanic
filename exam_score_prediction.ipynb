{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e3315ec",
   "metadata": {},
   "source": [
    "exam score prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7adca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99743283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed46a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a3ece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kagglehub[pandas-datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ba4b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install kagglehub[pandas-datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2474a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Point to the specific file inside the dataset\n",
    "file_path = \"Exam_Score_Prediction.csv\"\n",
    "\n",
    "df = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"kundanbedmutha/exam-score-prediction-dataset\",\n",
    "  file_path,\n",
    ")\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27c8e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c15c721",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce42c9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72e8a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508b7321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only columns that contain text (object type)\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(f\"Unique values in '{col}':\")\n",
    "    print(df[col].unique())\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af08cb6f",
   "metadata": {},
   "source": [
    "we assign numbers that represent a \"scale\" (0 or 1 to 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0392877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping for ranked variables\n",
    "ordinal_mapping = {\n",
    "    'sleep_quality': {'poor': 1, 'average': 2, 'good': 3},\n",
    "    'facility_rating': {'low': 1, 'medium': 2, 'high': 3},\n",
    "    'exam_difficulty': {'easy': 1, 'moderate': 2, 'hard': 3},\n",
    "    'internet_access': {'no': 0, 'yes': 1}\n",
    "}\n",
    "\n",
    "# Apply the mapping\n",
    "for col, val_map in ordinal_mapping.items():\n",
    "    df[col] = df[col].map(val_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55c2656",
   "metadata": {},
   "source": [
    "One-Hot Encoding for Nominal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bc602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert remaining text columns into 0 and 1 columns\n",
    "df_final = pd.get_dummies(df, columns=['gender', 'course', 'study_method'], drop_first=True)\n",
    "\n",
    "# Display the first few rows to see the new structure\n",
    "print(df_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7946826",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a07976",
   "metadata": {},
   "source": [
    "Distribution of the Target (exam_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b3018c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23de3381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(df_final['exam_score'], kde=True, color='teal')\n",
    "plt.title('Distribution of Exam Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeba7d1",
   "metadata": {},
   "source": [
    "Correlation Heatmap\n",
    "Close to 1: As the feature goes up, the score goes up (e.g., Study Hours).\n",
    "\n",
    "Close to -1: As the feature goes up, the score goes down (e.g., Difficulty).\n",
    "\n",
    "Close to 0: The feature has almost no impact on the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca66de4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "# Calculate correlation\n",
    "corr = df_final.corr()\n",
    "# Plot heatmap\n",
    "sns.heatmap(corr[['exam_score']].sort_values(by='exam_score', ascending=False), \n",
    "            annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation of All Features with Exam Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0ee2ee",
   "metadata": {},
   "source": [
    "for Linear Regression: Feature SelectionBased on the Correlation Heatmap, I decided to focus only on high-impact features and ignore \"noise\" variables with correlations close to zero (between $0.045$ and $-0.063$).Features Kept:study_hours (Strongest Predictor: 0.72)class_attendancesleep_hours & sleep_qualityfacility_ratingstudy_method_self-study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1f112e",
   "metadata": {},
   "source": [
    "Study Hours vs. Score (with Regression Line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb2b865",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.regplot(data=df_final, x='study_hours', y='exam_score', \n",
    "            scatter_kws={'alpha':0.3}, line_kws={'color':'red'})\n",
    "plt.title('Relationship: Study Hours vs. Exam Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94076692",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff42aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the target variable\n",
    "y = df_final['exam_score']\n",
    "\n",
    "# --- VERSION 1: High-Impact Subset (For Linear/Ridge/Lasso) ---\n",
    "linear_features = ['study_hours', 'class_attendance', 'sleep_hours', \n",
    "                   'sleep_quality', 'facility_rating', 'study_method_self-study']\n",
    "X_linear = df_final[linear_features]\n",
    "\n",
    "X_train_lin, X_test_lin, y_train, y_test = train_test_split(\n",
    "    X_linear, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# --- VERSION 2: All Features (For Decision Tree/Random Forest) ---\n",
    "X_forest = df_final.drop(['exam_score', 'student_id'], axis=1)\n",
    "\n",
    "X_train_rf, X_test_rf, _, _ = train_test_split(\n",
    "    X_forest, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Data splits created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9cd28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Dictionary of models with different characteristics\n",
    "models = {\n",
    "    \"Linear Regression (Subset)\": LinearRegression(),\n",
    "    \"Ridge (Subset)\": Ridge(alpha=1.0), \n",
    "    \"Lasso (Subset)\": Lasso(alpha=0.1),\n",
    "    \"Decision Tree (Full)\": DecisionTreeRegressor(max_depth=5, random_state=42),\n",
    "    \"Random Forest (Full)\": RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc2ad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Models\n",
    "models = {\n",
    "    \"Linear Regression (Subset)\": LinearRegression(),\n",
    "    \"Ridge (Subset)\": Ridge(alpha=1.0), \n",
    "    \"Lasso (Subset)\": Lasso(alpha=0.1),\n",
    "    \"Decision Tree (Full)\": DecisionTreeRegressor(max_depth=5, random_state=42),\n",
    "    \"Random Forest (Full)\": RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Select the correct split based on the model type\n",
    "    if \"(Subset)\" in name:\n",
    "        X_train_current, X_test_current = X_train_lin, X_test_lin\n",
    "    else:\n",
    "        X_train_current, X_test_current = X_train_rf, X_test_rf\n",
    "    \n",
    "    # 5-Fold Cross Validation\n",
    "    cv_scores = cross_val_score(model, X_train_current, y_train, cv=5, scoring='r2')\n",
    "    \n",
    "    # Train and test\n",
    "    model.fit(X_train_current, y_train)\n",
    "    test_score = model.score(X_test_current, y_test)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"CV R2 Mean\": cv_scores.mean(),\n",
    "        \"Test R2\": test_score\n",
    "    })\n",
    "\n",
    "# Format and display the results\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"Test R2\", ascending=False)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7640235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After your loop finishes:\n",
    "best_model_entry = max(results, key=lambda x: x['Test R2'])\n",
    "\n",
    "print(\"---  BEST MODEL PERFORMANCE ---\")\n",
    "print(f\"Model Name: {best_model_entry['Model']}\")\n",
    "print(f\"Test R2 Score: {best_model_entry['Test R2']:.4f}\")\n",
    "print(f\"Cross-Validation R2: {best_model_entry['CV R2 Mean']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4206a069",
   "metadata": {},
   "source": [
    "improve  Random Forest, we  to combine Hyperparameter Tuning with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8ada23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 1. Define the parameters you want to \"tune\"\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500],           # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],           # How deep each tree can grow\n",
    "    'min_samples_split': [2, 5, 10],           # Minimum samples required to split a node\n",
    "    'max_features': ['sqrt', 'log2', None]     # Number of features to consider at each split\n",
    "}\n",
    "\n",
    "# 2. Initialize the Grid Search\n",
    "# cv=5 means it will do 5-fold cross-validation for EACH combination\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestRegressor(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=5, \n",
    "    scoring='r2',\n",
    "    n_jobs=-1, # Uses all your CPU cores to speed it up\n",
    "    verbose=2  # Prints progress so you can see it working\n",
    ")\n",
    "\n",
    "# 3. Fit to your data\n",
    "# Using X_train_rf (the one with all features)\n",
    "grid_search.fit(X_train_rf, y_train)\n",
    "\n",
    "# 4. Results\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV R2 Score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc341473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best model found by the search\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set\n",
    "final_pred = best_rf.predict(X_test_rf)\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "print(f\"Final Tuned Test R2: {r2_score(y_test, final_pred):.4f}\")\n",
    "print(f\"Final Tuned MAE: {mean_absolute_error(y_test, final_pred):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
